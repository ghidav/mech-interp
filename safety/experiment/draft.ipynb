{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch as th\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "rs = 42\n",
    "\n",
    "with open('data/alpaca_data_cleaned.json', 'r') as f:\n",
    "    alpaca = json.load(f)\n",
    "\n",
    "alpaca = pd.DataFrame(alpaca)\n",
    "alpaca = alpaca.dropna()[alpaca['input'] == '']\n",
    "alpaca = alpaca.sample(12500, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_train = alpaca.iloc[:10000].drop('input', axis=1)\n",
    "alpaca_eval = alpaca.iloc[10000:12000].drop('input', axis=1)\n",
    "alpaca_heldout = alpaca.iloc[12000:].drop('input', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_train.to_json(orient='records', path_or_buf='training/alpaca_train_base.json')\n",
    "alpaca_eval.to_json(orient='records', path_or_buf='evaluation/alpaca_eval.json')\n",
    "alpaca_heldout.to_json(orient='records', path_or_buf='evaluation/alpaca_heldout.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/safe_instructions.json', 'r') as f:\n",
    "    safe_inst = json.load(f)\n",
    "\n",
    "safe_inst = pd.DataFrame(safe_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_ins_1 = safe_inst.iloc[:100]\n",
    "safe_ins_3 = safe_inst.iloc[:300]\n",
    "safe_ins_5 = safe_inst.iloc[:500]\n",
    "safe_ins_10 = safe_inst.iloc[:1000]\n",
    "safe_ins_20 = safe_inst.iloc[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([alpaca_train, safe_ins_1], axis=0).sample(frac=1, random_state=rs).drop('input', axis=1).to_json(orient='records', path_or_buf='training/alpaca_train_100.json')\n",
    "pd.concat([alpaca_train, safe_ins_3], axis=0).sample(frac=1, random_state=rs).drop('input', axis=1).to_json(orient='records', path_or_buf='training/alpaca_train_300.json')\n",
    "pd.concat([alpaca_train, safe_ins_5], axis=0).sample(frac=1, random_state=rs).drop('input', axis=1).to_json(orient='records', path_or_buf='training/alpaca_train_500.json')\n",
    "pd.concat([alpaca_train, safe_ins_10], axis=0).sample(frac=1, random_state=rs).drop('input', axis=1).to_json(orient='records', path_or_buf='training/alpaca_train_1000.json')\n",
    "pd.concat([alpaca_train, safe_ins_20], axis=0).sample(frac=1, random_state=rs).drop('input', axis=1).to_json(orient='records', path_or_buf='training/alpaca_train_2000.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confiigs\n",
    "configs = []\n",
    "\n",
    "# Add Llamas\n",
    "for repo, model in zip([\"meta-llama\", \"mistralai\"], ['Llama-2-7b-hf', 'Mistral-7B-v0.1']):\n",
    "    for i, safe in enumerate(['base', '100', '300', '500', '1000', '2000']):\n",
    "        for j in range(3):\n",
    "            configs.append({\n",
    "                \"train_data_general_path\": f\"training/alpaca_train_{safe}.json\",\n",
    "                \"output_model_name\": f\"{model}-lora-{safe}-rs-{j+1}\",\n",
    "                \"base_repository\": \"safety-lora\",\n",
    "                \"base_model\": f\"{repo}/{model}\",\n",
    "                \"dev_data_path\": \"evaluation/alpaca_eval.json\"\n",
    "            })\n",
    "\n",
    "with open('configs.json', 'w') as f:\n",
    "    json.dump(configs, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
