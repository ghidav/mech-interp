{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from tuned_lens.causal import extract_causal_bases\n",
    "from tuned_lens.nn.lenses import TunedLens, LogitLens, Unembed\n",
    "from transformer_lens import HookedTransformer \n",
    "import torch\n",
    "from typing import cast, Optional\n",
    "import math\n",
    "import torch as th\n",
    "import torch.distributions as D\n",
    "\n",
    "#safe_model = load_model(\"EleutherAI/pythia-160m\", tl_model_name=\"EleutherAI/pythia-160m\", device='cuda', n_devices=2, dtype=torch.bfloat16)\n",
    "model = HookedTransformer.from_pretrained('gpt2', fold_ln=False, device='cuda:0')\n",
    "n_layers = len(model.blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TunedLens(\n",
       "  (unembed): Unembed(\n",
       "    (final_norm): LayerNorm(\n",
       "      (hook_scale): HookPoint()\n",
       "      (hook_normalized): HookPoint()\n",
       "    )\n",
       "    (unembedding): Linear(in_features=768, out_features=50257, bias=True)\n",
       "  )\n",
       "  (layer_translators): ModuleList(\n",
       "    (0-11): 12 x Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_lens = TunedLens.from_unembed_and_pretrained(\n",
    "    unembed=Unembed(model),\n",
    "    lens_resource_id=\"gpt2\",\n",
    ")\n",
    "logit_lens = LogitLens.from_model(model)\n",
    "tuned_lens.to('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "prompts = pd.read_csv('data/prompts_ds2.csv')['prompt'][:8] # <-- change here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b132235c48414ee59c8faf152f9a52fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (768x50257 and 768x768)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m vec \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m ene \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m extract_causal_bases(tuned_lens, resid_post, k\u001b[38;5;241m=\u001b[39mk):\n\u001b[1;32m     17\u001b[0m     vec\u001b[38;5;241m.\u001b[39mappend(j\u001b[38;5;241m.\u001b[39mvectors[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n\u001b[1;32m     18\u001b[0m     ene\u001b[38;5;241m.\u001b[39mappend(j\u001b[38;5;241m.\u001b[39menergies[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n",
      "File \u001b[0;32m/mnt/sdb1/project/mech-interp/venv/lib/python3.9/site-packages/tuned_lens/causal/subspaces.py:110\u001b[0m, in \u001b[0;36mextract_causal_bases\u001b[0;34m(lens, hiddens, k, labels, max_iter, mode)\u001b[0m\n\u001b[1;32m    108\u001b[0m logits \u001b[38;5;241m=\u001b[39m lens(hiddens[i], i)\n\u001b[1;32m    109\u001b[0m log_p \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mlog_softmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 110\u001b[0m U \u001b[38;5;241m=\u001b[39m \u001b[43mlens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_hidden\u001b[49m\u001b[43m(\u001b[49m\u001b[43mU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# TODO not sure if we need transposes here\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Compute the baseline loss up front so that we can subtract it\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# from the post-ablation losses to get the loss increment\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/sdb1/project/mech-interp/venv/lib/python3.9/site-packages/tuned_lens/nn/lenses.py:309\u001b[0m, in \u001b[0;36mTunedLens.transform_hidden\u001b[0;34m(self, h, idx)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform hidden state from layer `idx`.\"\"\"\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# Note that we add the translator output residually, in contrast to the formula\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# in the paper. By parametrizing it this way we ensure that weight decay\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# regularizes the transform toward the identity, not the zero transformation.\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m h \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sdb1/project/mech-interp/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sdb1/project/mech-interp/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/sdb1/project/mech-interp/venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (768x50257 and 768x768)"
     ]
    }
   ],
   "source": [
    "cb_energies = []\n",
    "cb_vectors = []\n",
    "\n",
    "k = 10\n",
    "\n",
    "for i in range(len(prompts)):\n",
    "    tokens = model.to_tokens(prompts[i])\n",
    "    with torch.no_grad():\n",
    "        _, cache = model.run_with_cache(tokens)\n",
    "    \n",
    "    resid_post = torch.cat([cache[f'blocks.{l}.hook_resid_post'] for l in range(n_layers)]) # [b p dm]\n",
    "\n",
    "    vec = []\n",
    "    ene = []\n",
    "    \n",
    "    for j in extract_causal_bases(tuned_lens, resid_post, k=k):\n",
    "        vec.append(j.vectors[None, None, ...])\n",
    "        ene.append(j.energies[None, None, ...])\n",
    "\n",
    "    cb_vectors.append(torch.cat(vec, dim=1))\n",
    "    cb_energies.append(torch.cat(ene, dim=1))\n",
    "\n",
    "cb_vectors = torch.cat(cb_vectors, dim=0) # [prompt layer d_model k]\n",
    "cb_energies = torch.cat(cb_energies, dim=0) # [prompt layer d_model k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hooked run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.hook_points import HookPoint\n",
    "from jaxtyping import Float\n",
    "\n",
    "def subspace_ablation_hook(\n",
    "    rs: Float[torch.Tensor, \"batch pos d_model\"],\n",
    "    hook: HookPoint,\n",
    "    pos: list,\n",
    "    subspace: Float[torch.Tensor, \"d_model k\"],\n",
    "    sampled_rs: Float[torch.Tensor, \"batch pos k\"]\n",
    ") -> Float[torch.Tensor, \"batch pos d_model\"]:\n",
    "\n",
    "    print(torch.norm(subspace, dim=0), subspace.shape)\n",
    "    assert torch.allclose(torch.norm(subspace, dim=0), torch.ones_like(torch.norm(subspace, dim=0)), atol = 1e-8) \n",
    "\n",
    "    ablation = torch.zeros_like(rs[:,pos,:])\n",
    "    delta = rs[:, pos, :] - sampled_rs[:,pos,:] # batch d_model\n",
    "\n",
    "    P_u = subspace @ subspace.T #d_mod, d_mod\n",
    "    rs[:, pos, :] = rs[:, pos, :] + (P_u @ delta.T).T  \n",
    "\n",
    "    return rs + ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x' = x + P_u(\\tilde x âˆ’ x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What we used before \n",
    "\n",
    "def weighted_geom_mean(p, w):\n",
    "    return torch.exp((w * torch.log(p)).sum(-1) / w.sum(-1))\n",
    "\n",
    "def aitchison_weighted_similarity(p, q, w):\n",
    "    return (w * torch.log(p / weighted_geom_mean(p, w).unsqueeze(1)) * torch.log(q / weighted_geom_mean(q, w).unsqueeze(1))).sum(-1)\n",
    "\"\"\"\n",
    "\n",
    "def aitchison(\n",
    "    log_p: th.Tensor,\n",
    "    log_q: th.Tensor,\n",
    "    *,\n",
    "    weight: Optional[th.Tensor] = None,\n",
    "    dim: int = -1\n",
    ") -> th.Tensor:\n",
    "    \"\"\"Compute the (weighted) Aitchison inner product between log probability vectors.\n",
    "    The `weight` parameter can be used to downweight rare tokens in an LM's vocabulary.\n",
    "    See 'Changing the Reference Measure in the Simplex and Its Weighting Effects' by\n",
    "    Egozcue and Pawlowsky-Glahn (2016) for discussion.\n",
    "    \"\"\"\n",
    "    # Normalize the weights to sum to 1 if necessary\n",
    "    if weight is not None:\n",
    "        weight = weight / weight.sum(dim=dim, keepdim=True)\n",
    "\n",
    "    # Project to Euclidean space...\n",
    "    x = _clr(log_p, weight, dim=dim)\n",
    "    y = _clr(log_q, weight, dim=dim)\n",
    "\n",
    "    # Then compute the weighted dot product\n",
    "    return _weighted_mean(x * y, weight, dim=dim)\n",
    "\n",
    "\n",
    "def aitchison_similarity(\n",
    "    log_p: th.Tensor,\n",
    "    log_q: th.Tensor,\n",
    "    *,\n",
    "    weight: Optional[th.Tensor] = None,\n",
    "    dim: int = -1,\n",
    "    eps: float = 1e-8\n",
    ") -> th.Tensor:\n",
    "    \"\"\"Cosine similarity of log probability vectors with the Aitchison inner product.\n",
    "    Specifically, we compute <p, q> / max(||p|| * ||q||, eps), where ||p|| is the norm\n",
    "    induced by the Aitchison inner product: sqrt(<p, p>).\n",
    "    \"\"\"\n",
    "    affinity = aitchison(log_p, log_q, weight=weight, dim=dim)\n",
    "    norm_p = aitchison(log_p, log_p, weight=weight, dim=dim).sqrt()\n",
    "    norm_q = aitchison(log_q, log_q, weight=weight, dim=dim).sqrt()\n",
    "    return affinity / (norm_p * norm_q).clamp_min(eps)\n",
    "\n",
    "\n",
    "def _clr(\n",
    "    log_y: th.Tensor, weight: Optional[th.Tensor] = None, dim: int = -1\n",
    ") -> th.Tensor:\n",
    "    \"\"\"Apply a (weighted) centered logratio transform to a log probability vector.\n",
    "    This is equivalent to subtracting the geometric mean in log space, and it is one of\n",
    "    three main isomorphisms between the simplex and (n-1) dimensional Euclidean space.\n",
    "    See https://en.wikipedia.org/wiki/Compositional_data#Linear_transformations for\n",
    "    more information.\n",
    "    Args:\n",
    "        log_y: A log composition vector\n",
    "        weight: A normalized vector of non-negative weights to use for the geometric\n",
    "            mean. If `None`, a uniform reference distribution will be used.\n",
    "        dim: The dimension along which to compute the geometric mean.\n",
    "    Returns:\n",
    "        The centered logratio vector.\n",
    "    \"\"\"\n",
    "    # The geometric mean is simply the arithmetic mean in log space\n",
    "    return log_y - _weighted_mean(log_y, weight, dim=dim).unsqueeze(dim)\n",
    "\n",
    "\n",
    "def _weighted_mean(\n",
    "    x: th.Tensor, weight: Optional[th.Tensor] = None, dim: int = -1\n",
    ") -> th.Tensor:\n",
    "    \"\"\"Compute a weighted mean if `weight` is not `None`, else the unweighted mean.\"\"\"\n",
    "    if weight is None:\n",
    "        return x.mean(dim=dim)\n",
    "\n",
    "    # NOTE: `weight` is assumed to be non-negative and sum to 1.\n",
    "    return x.mul(weight).sum(dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7680., device='cuda:0') torch.Size([768, 10])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/dghilardi/mip/mech-interp/tuned_lens_test.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.27.243.182/home/dghilardi/mip/mech-interp/tuned_lens_test.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m model\u001b[39m.\u001b[39mblocks[l]\u001b[39m.\u001b[39mhook_resid_post\u001b[39m.\u001b[39madd_hook(temp_ablation_fn) \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.27.243.182/home/dghilardi/mip/mech-interp/tuned_lens_test.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B34.27.243.182/home/dghilardi/mip/mech-interp/tuned_lens_test.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m     _, hooked_cache \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mrun_with_cache(tokens)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.27.243.182/home/dghilardi/mip/mech-interp/tuned_lens_test.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m hooked_lens_layer\u001b[39m.\u001b[39mappend(hooked_cache[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblocks.\u001b[39m\u001b[39m{\u001b[39;00ml\u001b[39m}\u001b[39;00m\u001b[39m.hook_resid_post\u001b[39m\u001b[39m'\u001b[39m][:,p,:]) \u001b[39m# [1 dm]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.27.243.182/home/dghilardi/mip/mech-interp/tuned_lens_test.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m hooked_logit_layer\u001b[39m.\u001b[39mappend(hooked_cache[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mln_final.hook_normalized\u001b[39m\u001b[39m'\u001b[39m][:,p,:]) \u001b[39m# [1 dm]\u001b[39;00m\n",
      "File \u001b[0;32m~/mip/venv/lib/python3.9/site-packages/transformer_lens/HookedTransformer.py:630\u001b[0m, in \u001b[0;36mHookedTransformer.run_with_cache\u001b[0;34m(self, return_cache_object, remove_batch_dim, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_with_cache\u001b[39m(\n\u001b[1;32m    614\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mmodel_args, return_cache_object\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, remove_batch_dim\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    615\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    622\u001b[0m     Union[ActivationCache, Dict[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor]],\n\u001b[1;32m    623\u001b[0m ]:\n\u001b[1;32m    624\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Wrapper around `run_with_cache` in HookedRootModule.\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \n\u001b[1;32m    626\u001b[0m \u001b[39m    If return_cache_object is True, this will return an ActivationCache object, with a bunch of\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39m    useful HookedTransformer specific methods, otherwise it will return a dictionary of\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[39m    activations as in HookedRootModule.\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m     out, cache_dict \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mrun_with_cache(\n\u001b[1;32m    631\u001b[0m         \u001b[39m*\u001b[39;49mmodel_args, remove_batch_dim\u001b[39m=\u001b[39;49mremove_batch_dim, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    632\u001b[0m     )\n\u001b[1;32m    633\u001b[0m     \u001b[39mif\u001b[39;00m return_cache_object:\n\u001b[1;32m    634\u001b[0m         cache \u001b[39m=\u001b[39m ActivationCache(\n\u001b[1;32m    635\u001b[0m             cache_dict, \u001b[39mself\u001b[39m, has_batch_dim\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m remove_batch_dim\n\u001b[1;32m    636\u001b[0m         )\n",
      "File \u001b[0;32m~/mip/venv/lib/python3.9/site-packages/transformer_lens/hook_points.py:467\u001b[0m, in \u001b[0;36mHookedRootModule.run_with_cache\u001b[0;34m(self, names_filter, device, remove_batch_dim, incl_bwd, reset_hooks_end, clear_contexts, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    457\u001b[0m cache_dict, fwd, bwd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_caching_hooks(\n\u001b[1;32m    458\u001b[0m     names_filter, incl_bwd, device, remove_batch_dim\u001b[39m=\u001b[39mremove_batch_dim\n\u001b[1;32m    459\u001b[0m )\n\u001b[1;32m    461\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhooks(\n\u001b[1;32m    462\u001b[0m     fwd_hooks\u001b[39m=\u001b[39mfwd,\n\u001b[1;32m    463\u001b[0m     bwd_hooks\u001b[39m=\u001b[39mbwd,\n\u001b[1;32m    464\u001b[0m     reset_hooks_end\u001b[39m=\u001b[39mreset_hooks_end,\n\u001b[1;32m    465\u001b[0m     clear_contexts\u001b[39m=\u001b[39mclear_contexts,\n\u001b[1;32m    466\u001b[0m ):\n\u001b[0;32m--> 467\u001b[0m     model_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49mmodel_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs)\n\u001b[1;32m    468\u001b[0m     \u001b[39mif\u001b[39;00m incl_bwd:\n\u001b[1;32m    469\u001b[0m         model_out\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/mip/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mip/venv/lib/python3.9/site-packages/transformer_lens/HookedTransformer.py:551\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[39mif\u001b[39;00m shortformer_pos_embed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    547\u001b[0m         shortformer_pos_embed \u001b[39m=\u001b[39m shortformer_pos_embed\u001b[39m.\u001b[39mto(\n\u001b[1;32m    548\u001b[0m             devices\u001b[39m.\u001b[39mget_device_for_block_index(i, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg)\n\u001b[1;32m    549\u001b[0m         )\n\u001b[0;32m--> 551\u001b[0m     residual \u001b[39m=\u001b[39m block(\n\u001b[1;32m    552\u001b[0m         residual,\n\u001b[1;32m    553\u001b[0m         \u001b[39m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[1;32m    554\u001b[0m         \u001b[39m# block\u001b[39;49;00m\n\u001b[1;32m    555\u001b[0m         past_kv_cache_entry\u001b[39m=\u001b[39;49mpast_kv_cache[i]\n\u001b[1;32m    556\u001b[0m         \u001b[39mif\u001b[39;49;00m past_kv_cache \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    557\u001b[0m         \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    558\u001b[0m         shortformer_pos_embed\u001b[39m=\u001b[39;49mshortformer_pos_embed,\n\u001b[1;32m    559\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    560\u001b[0m     )  \u001b[39m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \u001b[39mif\u001b[39;00m stop_at_layer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    563\u001b[0m     \u001b[39m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    564\u001b[0m     \u001b[39mreturn\u001b[39;00m residual\n",
      "File \u001b[0;32m~/mip/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mip/venv/lib/python3.9/site-packages/transformer_lens/components.py:1063\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m   1059\u001b[0m     normalized_resid_mid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln2(mlp_in)\n\u001b[1;32m   1060\u001b[0m     mlp_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhook_mlp_out(\n\u001b[1;32m   1061\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp(normalized_resid_mid)\n\u001b[1;32m   1062\u001b[0m     )  \u001b[39m# [batch, pos, d_model]\u001b[39;00m\n\u001b[0;32m-> 1063\u001b[0m     resid_post \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhook_resid_post(\n\u001b[1;32m   1064\u001b[0m         resid_mid \u001b[39m+\u001b[39;49m mlp_out\n\u001b[1;32m   1065\u001b[0m     )  \u001b[39m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mparallel_attn_mlp:\n\u001b[1;32m   1067\u001b[0m     \u001b[39m# Dumb thing done by GPT-J, both MLP and Attn read from resid_pre and write to resid_post, no resid_mid used.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m     \u001b[39m# In GPT-J, LN1 and LN2 are tied, in GPT-NeoX they aren't.\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m     normalized_resid_pre_2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln2(\n\u001b[1;32m   1070\u001b[0m         resid_pre\n\u001b[1;32m   1071\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39muse_hook_mlp_in\n\u001b[1;32m   1072\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhook_mlp_in(resid_pre\u001b[39m.\u001b[39mclone())\n\u001b[1;32m   1073\u001b[0m     )\n",
      "File \u001b[0;32m~/mip/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1547\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1545\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, args, kwargs, result)\n\u001b[1;32m   1546\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1547\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39;49m, args, result)\n\u001b[1;32m   1549\u001b[0m \u001b[39mif\u001b[39;00m hook_result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1550\u001b[0m     result \u001b[39m=\u001b[39m hook_result\n",
      "File \u001b[0;32m~/mip/venv/lib/python3.9/site-packages/transformer_lens/hook_points.py:65\u001b[0m, in \u001b[0;36mHookPoint.add_hook.<locals>.full_hook\u001b[0;34m(module, module_input, module_output)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfull_hook\u001b[39m(module, module_input, module_output):\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m hook(module_output, hook\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n",
      "\u001b[1;32m/home/dghilardi/mip/mech-interp/tuned_lens_test.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.27.243.182/home/dghilardi/mip/mech-interp/tuned_lens_test.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msubspace_ablation_hook\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.27.243.182/home/dghilardi/mip/mech-interp/tuned_lens_test.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     rs: Float[torch\u001b[39m.\u001b[39mTensor, \u001b[39m\"\u001b[39m\u001b[39mbatch pos d_model\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.27.243.182/home/dghilardi/mip/mech-interp/tuned_lens_test.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     hook: HookPoint,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.27.243.182/home/dghilardi/mip/mech-interp/tuned_lens_test.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     sampled_rs: Float[torch\u001b[39m.\u001b[39mTensor, \u001b[39m\"\u001b[39m\u001b[39mbatch pos k\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.27.243.182/home/dghilardi/mip/mech-interp/tuned_lens_test.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Float[torch\u001b[39m.\u001b[39mTensor, \u001b[39m\"\u001b[39m\u001b[39mbatch pos d_model\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.27.243.182/home/dghilardi/mip/mech-interp/tuned_lens_test.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mnorm(subspace, \u001b[39m0\u001b[39m), subspace\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B34.27.243.182/home/dghilardi/mip/mech-interp/tuned_lens_test.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39massert\u001b[39;00m torch\u001b[39m.\u001b[39mallclose(torch\u001b[39m.\u001b[39mnorm(subspace, \u001b[39m0\u001b[39m), torch\u001b[39m.\u001b[39mones_like(torch\u001b[39m.\u001b[39mnorm(subspace, \u001b[39m0\u001b[39m)), atol \u001b[39m=\u001b[39m \u001b[39m1e-8\u001b[39m) \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.27.243.182/home/dghilardi/mip/mech-interp/tuned_lens_test.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m     ablation \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(rs[:,pos,:])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.27.243.182/home/dghilardi/mip/mech-interp/tuned_lens_test.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     delta \u001b[39m=\u001b[39m rs[:, pos, :] \u001b[39m-\u001b[39m sampled_rs[:,pos,:] \u001b[39m# batch d_model\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "# Hooked run\n",
    "model.reset_hooks(including_permanent=True)\n",
    "sample_idx = torch.randperm(len(prompts))\n",
    "\n",
    "_, pre_cache = model.run_with_cache(model.to_tokens(prompts.iloc[-1]))\n",
    "\n",
    "clean_rs = []\n",
    "for i, idx in enumerate(sample_idx):\n",
    "    tokens = model.to_tokens(prompts[i])\n",
    "\n",
    "    # Clean cache\n",
    "    with torch.no_grad():\n",
    "        _, clean_cache = model.run_with_cache(tokens)\n",
    "    clean_rs = torch.cat([clean_cache[f'blocks.{l}.hook_resid_post'] for l in range(n_layers)], 0) # [l p dm]\n",
    "    clean_logits = clean_cache[f'ln_final.hook_normalized'] # [1 p dm]\n",
    "\n",
    "\n",
    "    # Hooked cache\n",
    "    hooked_lens = []\n",
    "    hooked_logits = None\n",
    "\n",
    "    for l in range(n_layers-1):\n",
    "\n",
    "        hooked_lens_layer = []\n",
    "        hooked_logit_layer = []\n",
    "        \n",
    "        for p in range(len(tokens)):\n",
    "            model.reset_hooks(including_permanent = True)\n",
    "\n",
    "            temp_ablation_fn = partial(subspace_ablation_hook, pos=p, subspace=cb_vectors[i, l], sampled_rs=pre_cache[f'blocks.{l}.hook_resid_post'])\n",
    "            model.blocks[l].hook_resid_post.add_hook(temp_ablation_fn) \n",
    "\n",
    "            with torch.no_grad():\n",
    "                _, hooked_cache = model.run_with_cache(tokens)\n",
    "            hooked_lens_layer.append(hooked_cache[f'blocks.{l}.hook_resid_post'][:,p,:]) # [1 dm]\n",
    "            hooked_logit_layer.append(hooked_cache[f'ln_final.hook_normalized'][:,p,:]) # [1 dm]\n",
    "\n",
    "        #torch cat with layer\n",
    "        hooked_lens.append(torch.cat(hooked_lens_layer, dim=0)[None, ...]) #[1 p dm]\n",
    "        if hooked_logits is None:\n",
    "            hooked_logits = torch.cat(hooked_logit_layer, dim=0)[None, ...] # [1 p dm]\n",
    "        \n",
    "    hooked_lens = torch.cat(hooked_lens, dim = 0) # [l p dm]\n",
    "    \n",
    "    # Compute Aitchison similarity\n",
    "    simil = []\n",
    "\n",
    "    response = torch.softmax(torch.log(model.unembed(hooked_logits).softmax(-1)) - torch.log(model.unembed(clean_logits).softmax(-1)), -1)[0] # [p dv]\n",
    "    w = model.unembed(clean_logits).softmax(-1)[0]\n",
    "\n",
    "    for l in range(n_layers-1):\n",
    "        with torch.no_grad():\n",
    "            stimuli = torch.softmax(torch.log(logit_lens(hooked_lens[l], l).softmax(-1)) - torch.log(logit_lens(clean_rs[l], l).softmax(-1)), -1) # [p dv]\n",
    "        \n",
    "        #print(aitchison_weighted_similarity(stimuli, response, w))\n",
    "        \n",
    "        simil.append((aitchison_similarity(stimuli, response, weight=w)).mean(-1))\n",
    "\n",
    "    pre_cache = clean_cache\n",
    "\n",
    "    print(simil) # l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]], device='cuda:0')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hooked_rs[0] == clean_rs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(logit_lens(hooked_rs[l], l).softmax(-1)) - torch.log(logit_lens(clean_rs[l], l).softmax(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9898e-05, 1.9898e-05, 1.9898e-05,  ..., 1.9898e-05, 1.9898e-05,\n",
       "         1.9898e-05],\n",
       "        [1.9898e-05, 1.9898e-05, 1.9898e-05,  ..., 1.9898e-05, 1.9898e-05,\n",
       "         1.9898e-05],\n",
       "        [1.9898e-05, 1.9898e-05, 1.9898e-05,  ..., 1.9898e-05, 1.9898e-05,\n",
       "         1.9898e-05],\n",
       "        ...,\n",
       "        [1.9898e-05, 1.9898e-05, 1.9898e-05,  ..., 1.9898e-05, 1.9898e-05,\n",
       "         1.9898e-05],\n",
       "        [1.9898e-05, 1.9898e-05, 1.9898e-05,  ..., 1.9898e-05, 1.9898e-05,\n",
       "         1.9898e-05],\n",
       "        [1.9898e-05, 1.9898e-05, 1.9898e-05,  ..., 1.9898e-05, 1.9898e-05,\n",
       "         1.9898e-05]], device='cuda:0')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = 2\n",
    "torch.softmax(torch.log(logit_lens(hooked_rs[l], l).softmax(-1)) - torch.log(logit_lens(clean_rs[l], l).softmax(-1)), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 50257])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_lens(clean_rs[0, None], 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw and int caches\n",
    "_, int_cache = []\n",
    "_, raw_cache = []\n",
    "\n",
    "\n",
    "for l in range(n_layers): # iterate trough layers\n",
    "\n",
    "    # To compute aitchinson sim you need 4 distributions\n",
    "    stimul_inter = \n",
    "    stimul_raw =  \n",
    "\n",
    "    respon_int = \n",
    "    respon_raw ="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
